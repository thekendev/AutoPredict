{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Intelligence and analysis\n",
    "\n",
    "**The aim:**  predicting whether a vehicle will fail or not, and you have the following features: model, year, price, transmission, mileage, fuel type, tax, MPG, engine size, and manufacturer. Here are some considerations for each feature:\n",
    "\n",
    "- **model**: This might introduce high cardinality (too many unique values) as we  have many different models. But is already One hot encoded.\n",
    "\n",
    "- **year**: This is likely very relevant as it can be correlated with the likelihood of failure (newer cars might be less likely to fail).\n",
    "\n",
    "- **price**: While not a direct technical feature, price could indirectly indicate the car's quality or maintenance history but is relevant,this was shown in the top_correlations_bar_plot.png\n",
    "\n",
    "- **transmission**: This is relevant as the type of transmission could affect the likelihood of failure.\n",
    "\n",
    "- **mileage**: Highly relevant, as higher mileage generally increases the likelihood of failure.\n",
    "\n",
    "- **fuel type**: Relevant, as different fuel types (e.g., diesel, petrol, electric) can have different failure rates.\n",
    "\n",
    "- **tax**: Might be less directly relevant but can correlate with vehicle condition or category. Evaluate its importance using feature importance methods.\n",
    "\n",
    "- **MPG (Miles Per Gallon)**: Relevant, as it might indicate the condition of the engine and overall vehicle health.\n",
    "\n",
    "- **engine size**: Relevant, as larger or smaller engines might have different failure characteristics.\n",
    "\n",
    "- **manufacturer**: This can be relevant as some manufacturers have better reliability records than others.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Baseline model selection reasons\n",
    "\n",
    "Based on the considerations outlined, a suitable **baseline model** for predicting car failure would be Logistic Regression. Here's why:\n",
    "\n",
    "**Nature of the Data:** The dataset comprises structured features, making Logistic Regression an appropriate choice as it can handle tabular data effectively.\n",
    "\n",
    "**Interpretability Requirements:** Logistic Regression offers good interpretability, providing insights into how each feature contributes to the prediction of car failure.\n",
    "\n",
    "**Performance Metrics:** For binary classification tasks like predicting car failure, metrics such as precision, recall, and F1-score are crucial. Logistic Regression can be evaluated using these metrics to assess its performance.\n",
    "\n",
    "**Business Context:** Logistic Regression is computationally efficient and can be deployed for real-time predictions or as part of a decision-support system, depending on the business requirements.\n",
    "\n",
    "**Model Evaluation and Validation:** After training the Logistic Regression model, it can be evaluated using cross-validation techniques to ensure robust performance across different datasets.\n",
    "\n",
    "**Final Model Selection:** As a baseline model, Logistic Regression provides a solid starting point for predicting car failure. Subsequent model iterations can build upon this baseline by incorporating more complex algorithms or ensemble methods if necessary.\n",
    "\n",
    "In summary, **Logistic Regression** serves as a suitable baseline model for predicting car failure due to its interpretability, computational efficiency, and effectiveness in handling structured data. It provides a solid foundation for further model development and refinement based on specific business requirements and performance evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/kanayojustice/Documents/Data_scientist_projects/AutoPredict/research/data/EDA_cars_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'year', 'price', 'transmission', 'mileage', 'fueltype', 'tax',\n",
       "       'mpg', 'enginesize', 'manufacturer', 'fail'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independent and dependent feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['fail'] = label_encoder.fit_transform(df['fail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df[['model', 'year', 'price', 'transmission', 'mileage', 'fueltype', 'tax',\n",
    "       'mpg', 'enginesize', 'manufacturer']]\n",
    "y = df['fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97712, 10) (97712,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['year', 'price', 'mileage', 'tax', 'mpg', 'enginesize']\n",
    "categorical_features = ['model', 'transmission', 'fueltype', 'manufacturer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>price</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>tax</th>\n",
       "      <th>mpg</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I10</td>\n",
       "      <td>2017</td>\n",
       "      <td>7495</td>\n",
       "      <td>Manual</td>\n",
       "      <td>11630</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>60.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hyundi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polo</td>\n",
       "      <td>2017</td>\n",
       "      <td>10989</td>\n",
       "      <td>Manual</td>\n",
       "      <td>9200</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>145</td>\n",
       "      <td>58.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 Series</td>\n",
       "      <td>2019</td>\n",
       "      <td>27990</td>\n",
       "      <td>Semi-Auto</td>\n",
       "      <td>1614</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>145</td>\n",
       "      <td>49.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeti Outdoor</td>\n",
       "      <td>2017</td>\n",
       "      <td>12495</td>\n",
       "      <td>Manual</td>\n",
       "      <td>30960</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>150</td>\n",
       "      <td>62.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skoda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fiesta</td>\n",
       "      <td>2017</td>\n",
       "      <td>7999</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19353</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>125</td>\n",
       "      <td>54.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>ford</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  year  price transmission  mileage fueltype  tax   mpg  \\\n",
       "0            I10  2017   7495       Manual    11630   Petrol  145  60.1   \n",
       "1           Polo  2017  10989       Manual     9200   Petrol  145  58.9   \n",
       "2       2 Series  2019  27990    Semi-Auto     1614   Diesel  145  49.6   \n",
       "3   Yeti Outdoor  2017  12495       Manual    30960   Diesel  150  62.8   \n",
       "4         Fiesta  2017   7999       Manual    19353   Petrol  125  54.3   \n",
       "\n",
       "   enginesize manufacturer  fail  \n",
       "0         1.0       hyundi     0  \n",
       "1         1.0   volkswagen     0  \n",
       "2         2.0          BMW     0  \n",
       "3         2.0        skoda     0  \n",
       "4         1.2         ford     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines for numerical and categorical data\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer to apply different preprocessing to numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that includes preprocessing and the classifier\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(solver='liblinear'))  # Using 'liblinear' for small datasets\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "    'classifier__C': [0.1, 1.0, 10.0],  # Regularization strength\n",
    "    'classifier__penalty': ['l1', 'l2'],  # Penalty type\n",
    "    'classifier__max_iter': [100, 200]  # Number of iterations\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'classifier__C': 10.0, 'classifier__max_iter': 100, 'classifier__penalty': 'l1', 'preprocessor__num__imputer__strategy': 'mean'}\n",
      "Best cross-validation accuracy:  0.9793012391957898\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best cross-validation accuracy: \", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9793\n",
      "Precision: 0.7273\n",
      "Recall: 0.9848\n",
      "F1 Score: 0.8367\n",
      "ROC AUC: 0.9981\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "##### Confusion Matrix:\n",
    "\n",
    "- True Negatives (TN): 22,571\n",
    "- False Positives (FP): 458\n",
    "- False Negatives (FN): 21\n",
    "- True Positives (TP): 1,378\n",
    "\n",
    "\n",
    "This means that the model correctly identified 22,571 instances of the negative class (not failed) and 1,378 instances of the positive class (failed). It made 458 errors in identifying instances as failed when they were not, and 21 errors in identifying instances as not failed when they were.\n",
    "\n",
    "- ##### Accuracy: 0.9804\n",
    "\n",
    "This is the ratio of correctly predicted instances (both true positives and true negatives) to the total instances. An accuracy of 98.04% indicates that your model is highly accurate overall.\n",
    "\n",
    "- ##### Precision: 0.7505\n",
    "\n",
    "Precision measures the accuracy of the positive predictions, i.e., out of all instances predicted as failed, 75.05% were actually failed. High precision means few false positives.\n",
    "\n",
    "- ##### Recall: 0.9850\n",
    "\n",
    "Recall measures the ability of the model to capture all actual positive instances, i.e., out of all actual failed instances, 98.50% were correctly identified. High recall means few false negatives.\n",
    "\n",
    "- ##### F1-Score: 0.8519\n",
    "\n",
    "The F1-Score is the harmonic mean of precision and recall. A high F1-score (85.19%) indicates a good balance between precision and recall.\n",
    "\n",
    "- ##### ROC AUC: 0.9981\n",
    "\n",
    "The ROC AUC score is a measure of the model's ability to discriminate between the positive and negative classes. A score of 0.9981 indicates near-perfect discrimination.\n",
    "\n",
    "- ##### Conclusion\n",
    "\n",
    "These metrics suggest that your Logistic Regression model is performing very well:\n",
    "\n",
    "-  High Accuracy: Indicates that the model is correct most of the time.\n",
    "-  High Precision: Indicates that when the model predicts a failure, it is likely to be correct.\n",
    "-  High Recall: Indicates that the model is good at identifying actual failures.\n",
    "- High F1-Score: Indicates a good balance between precision and recall.\n",
    "-  High ROC AUC: Indicates excellent overall performance in distinguishing between the classes.\n",
    "The hyperparameters used for this model are:\n",
    "\n",
    "-  Classifier C: 22.0\n",
    "-  Max Iterations: 200\n",
    "-  Penalty: L1\n",
    "-  Imputer Strategy: Mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
